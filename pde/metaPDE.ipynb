{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b53381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt as edt\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418247c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSDF(Dataset):\n",
    "    def __init__(self, split='train', size=64, sample_points=None, data_root='./data'):\n",
    "        self.size = size\n",
    "        self.sample_points = sample_points\n",
    "        self.ds = datasets.MNIST(data_root, train=(split=='train'), download=True)\n",
    "        self.to_tensor = transforms.Compose([\n",
    "            transforms.Resize((size, size), antialias=True),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        # compat meshgrid\n",
    "        ys, xs = torch.linspace(-1,1,size), torch.linspace(-1,1,size)\n",
    "        yy, xx = torch.meshgrid(ys, xs)  # works everywhere\n",
    "        self.coords_full = torch.stack([xx, yy], dim=-1).reshape(-1, 2)\n",
    "\n",
    "    def __len__(self): return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_pil, _ = self.ds[idx]\n",
    "        img = self.to_tensor(img_pil)[0].numpy()\n",
    "        mask = (img >= 0.5).astype(np.uint8)\n",
    "\n",
    "        # signed distance (negative inside), normalized by diagonal\n",
    "        dist_out = edt(1 - mask).astype(np.float32)\n",
    "        dist_in  = edt(mask).astype(np.float32)\n",
    "        sdf = (dist_out - dist_in) / np.sqrt(self.size**2 + self.size**2)\n",
    "\n",
    "        coords = self.coords_full\n",
    "        sdf_flat = torch.from_numpy(sdf).view(-1,1)\n",
    "\n",
    "        if self.sample_points is not None and self.sample_points < coords.shape[0]:\n",
    "            ids = torch.randperm(coords.shape[0])[:self.sample_points]\n",
    "            coords, sdf_flat = coords[ids], sdf_flat[ids]\n",
    "\n",
    "        return {\n",
    "            \"idx\": idx,\n",
    "            \"coords\": coords.float(),           # [N,2]\n",
    "            \"sdf\": sdf_flat.float(),            # [N,1]\n",
    "            \"sdf_full\": torch.from_numpy(sdf)[None].float()  # [1,H,W]\n",
    "            # \"label\": label,  # optional\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c22fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azhir/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1739474892959/work/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create dataset\n",
    "ds = MNISTSDF(split='train', size=64, sample_points=None)\n",
    "\n",
    "# pick an index to view\n",
    "idx_to_view = 5\n",
    "sample = ds[idx_to_view]\n",
    "\n",
    "# unpack\n",
    "coords = sample[\"coords\"]\n",
    "sdf_full = sample[\"sdf_full\"].numpy()[0]  # [H,W]\n",
    "digit_label = idx_to_view  # optional\n",
    "\n",
    "# plot SDF heatmap and Binary Mask with the same height\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "# Plot SDF heatmap\n",
    "im0 = axes[0].imshow(sdf_full, cmap='seismic', origin='lower', vmin=-1, vmax=1)\n",
    "axes[0].set_title(f\"SDF Heatmap (Index {idx_to_view})\")\n",
    "axes[0].axis('off')\n",
    "fig.colorbar(im0, ax=axes[0], label='Signed Distance')\n",
    "\n",
    "# Plot Binary Mask\n",
    "binary_mask = (sdf_full < 0).astype(float)\n",
    "im1 = axes[1].imshow(binary_mask, cmap='gray', origin='lower')\n",
    "axes[1].set_title(f\"Binary Mask (Index {idx_to_view})\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247d6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for full grids (good for viz) or subsampled (fast DeepSDF)\n",
    "ds_full  = MNISTSDF(split='train', size=64, sample_points=None)\n",
    "ds_sub   = MNISTSDF(split='train', size=64, sample_points=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95067d",
   "metadata": {},
   "source": [
    "# Model DeepSDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1160f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DeepSDF(nn.Module):\n",
    "#     def __init__(self, z_dim=64, width=128, depth=4):\n",
    "#         super().__init__()\n",
    "#         self.z_dim = z_dim\n",
    "#         layers=[]; last=2+z_dim\n",
    "#         for _ in range(depth):\n",
    "#             layers += [nn.Linear(last, width), nn.ReLU(inplace=True)]\n",
    "#             last = width\n",
    "#         layers += [nn.Linear(last, 1)]\n",
    "#         self.net = nn.Sequential(*layers)\n",
    "#     def forward(self, coords, z):\n",
    "#         if z.dim()==1: z = z[None,:]\n",
    "#         N = coords.shape[0]\n",
    "#         zrep = z[:,None,:].expand(1,N,z.shape[-1]).reshape(N,-1)\n",
    "#         return self.net(torch.cat([coords, zrep], -1))\n",
    "\n",
    "class DeepSDF(nn.Module):\n",
    "    def __init__(self, z_dim=64, width=128, depth=4):\n",
    "        super().__init__()\n",
    "        layers = []; last = 2 + z_dim\n",
    "        for _ in range(depth):\n",
    "            layers += [nn.Linear(last, width), nn.ReLU(inplace=True)]\n",
    "            last = width\n",
    "        layers += [nn.Linear(last, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, coords, z):\n",
    "        # coords: (B,N,2) or (N,2); z: (B,D) or (D,)\n",
    "        if coords.dim() == 2:\n",
    "            coords = coords[None, ...]\n",
    "        if z.dim() == 1:\n",
    "            z = z[None, ...]\n",
    "        B, N, _ = coords.shape\n",
    "        zrep = z[:, None, :].expand(B, N, z.shape[-1])\n",
    "        x = torch.cat([coords, zrep], dim=-1).reshape(B * N, -1)\n",
    "        out = self.net(x).reshape(B, N, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def sdf_loss(pred, gt, band=0.2):\n",
    "    p = pred.squeeze(-1); g = gt.squeeze(-1)\n",
    "    near = (g.abs() < band).float()\n",
    "    l_sdf = (near * (p - g).abs()).mean()\n",
    "    occ = torch.sigmoid(-p)                 # negative => inside\n",
    "    l_occ = F.binary_cross_entropy(occ, (g < 0).float())\n",
    "    return l_sdf + 0.5*l_occ\n",
    "\n",
    "def clamped_l1(pred, gt, δ=0.1):\n",
    "    return torch.clamp((pred-gt).abs(), max=δ).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b83034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- data ---\n",
    "def collate(batch):\n",
    "    coords = torch.stack([b[\"coords\"]   for b in batch], 0)  # (B,N,2)\n",
    "    sdf    = torch.stack([b[\"sdf\"]      for b in batch], 0)  # (B,N,1)\n",
    "    idx    = torch.tensor([b[\"idx\"]     for b in batch], dtype=torch.long)\n",
    "    return coords, sdf, idx\n",
    "\n",
    "train_ds = MNISTSDF(split='train', size=64, sample_points=4096)\n",
    "# create dataset\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=32, shuffle=True,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Use your MNISTSDF class; subsample for speed if needed\n",
    "# train_ds = MNISTSDF(split='train', size=64, sample_points=4096)\n",
    "# train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf2f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1547908/2120221253.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/home/azhir/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1547908/2120221253.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/azhir/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m opt_z.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.amp.autocast():\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# (B,N,1)\u001b[39;00m\n\u001b[32m     28\u001b[39m     loss = sdf_loss(pred, sdf) + λ * z.pow(\u001b[32m2\u001b[39m).mean()\n\u001b[32m     30\u001b[39m scaler.scale(loss).backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mDeepSDF.forward\u001b[39m\u001b[34m(self, coords, z)\u001b[39m\n\u001b[32m     34\u001b[39m zrep = z[:, \u001b[38;5;28;01mNone\u001b[39;00m, :].expand(B, N, z.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m     35\u001b[39m x = torch.cat([coords, zrep], dim=-\u001b[32m1\u001b[39m).reshape(B * N, -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.reshape(B, N, \u001b[32m1\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# --- data ---\n",
    "def collate(batch):\n",
    "    coords = torch.stack([b[\"coords\"]   for b in batch], 0)  # (B,N,2)\n",
    "    sdf    = torch.stack([b[\"sdf\"]      for b in batch], 0)  # (B,N,1)\n",
    "    idx    = torch.tensor([b[\"idx\"]     for b in batch], dtype=torch.long)\n",
    "    return coords, sdf, idx\n",
    "\n",
    "train_ds = MNISTSDF(split='train', size=64, sample_points=4096)\n",
    "# create dataset\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=32, shuffle=True,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = DeepSDF(z_dim=64, width=128, depth=4).to(device)\n",
    "\n",
    "latents = nn.Embedding(len(train_ds), 64, sparse=True).to(device)\n",
    "nn.init.normal_(latents.weight, mean=0.0, std=0.01)\n",
    "\n",
    "opt_theta = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "opt_z     = torch.optim.SparseAdam(latents.parameters(), lr=1e-3)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "λ = 1e-3  # a bit stronger prior is helpful on MNIST\n",
    "\n",
    "for ep in range(1, 6):\n",
    "    model.train(); losses=[]\n",
    "    for coords, sdf, idx in train_loader:\n",
    "        coords = coords.to(device, non_blocking=True)\n",
    "        sdf    = sdf.to(device, non_blocking=True)\n",
    "        idx    = idx.to(device, non_blocking=True)\n",
    "\n",
    "        z = latents(idx)  # (B,64)\n",
    "\n",
    "        opt_theta.zero_grad(set_to_none=True)\n",
    "        opt_z.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(coords, z)          # (B,N,1)\n",
    "            loss = sdf_loss(pred, sdf) + λ * z.pow(2).mean()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt_theta); scaler.step(opt_z)\n",
    "        scaler.update()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    print(f\"epoch {ep} | train {np.mean(losses):.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# ---------- loss ----------\n",
    "@torch.cuda.amp.autocast(enabled=False)\n",
    "def sdf_occ_loss(pred_sdf, gt_sdf, band=0.2):\n",
    "    # pred_sdf, gt_sdf: (B,N,1)\n",
    "    p = pred_sdf.squeeze(-1)\n",
    "    g = gt_sdf.squeeze(-1)\n",
    "\n",
    "    # near-surface L1\n",
    "    near = (g.abs() < band).float()\n",
    "    l_sdf = (near * (p - g).abs()).sum() / (near.sum().clamp_min(1.0))\n",
    "\n",
    "    # occupancy/sign (inside if sdf<0)\n",
    "    occ_pred = torch.sigmoid(-p)\n",
    "    occ_tgt  = (g < 0).float()\n",
    "    l_occ = F.binary_cross_entropy(occ_pred, occ_tgt)\n",
    "\n",
    "    return l_sdf + 0.5 * l_occ\n",
    "\n",
    "# ---------- fast trainer ----------\n",
    "def train_deepsdf_fast(\n",
    "    train_ds, model, device=\"cuda\",\n",
    "    z_dim=64, batch_size=32, points_per_step=4096,\n",
    "    lr_theta=5e-4, lr_z=1e-3, weight_decay=1e-4,\n",
    "    lambda_z=1e-3, epochs=5, num_workers=4, amp=True, compile_model=True\n",
    "):\n",
    "    loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True, persistent_workers=(num_workers>0),\n",
    "        collate_fn=lambda batch: (\n",
    "            torch.stack([b[\"coords\"] for b in batch], 0),  # (B,N,2)\n",
    "            torch.stack([b[\"sdf\"]    for b in batch], 0),  # (B,N,1)\n",
    "            torch.tensor([b[\"idx\"]   for b in batch], dtype=torch.long),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # per-sample latents (sparse updates)\n",
    "    latents = nn.Embedding(len(train_ds), z_dim, sparse=True).to(device)\n",
    "    nn.init.normal_(latents.weight, mean=0.0, std=0.01)\n",
    "\n",
    "    model = model.to(device)\n",
    "    if compile_model and hasattr(torch, \"compile\"):\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    opt_theta = torch.optim.AdamW(model.parameters(), lr=lr_theta, weight_decay=weight_decay)\n",
    "    opt_z     = torch.optim.SparseAdam(latents.parameters(), lr=lr_z)\n",
    "\n",
    "    # cosine LR (optional but nice)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt_theta, T_max=epochs, eta_min=lr_theta*0.1)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for coords, sdf, idx in loader:\n",
    "            coords = coords.to(device, non_blocking=True)  # (B,N,2)\n",
    "            sdf    = sdf.to(device, non_blocking=True)     # (B,N,1)\n",
    "            idx    = idx.to(device, non_blocking=True)     # (B,)\n",
    "\n",
    "            # subsample points per step for speed\n",
    "            B, N, _ = coords.shape\n",
    "            if N > points_per_step:\n",
    "                sel = torch.randint(0, N, (points_per_step,), device=device)\n",
    "                coords = coords[:, sel]\n",
    "                sdf    = sdf[:, sel]\n",
    "\n",
    "            z = latents(idx)  # (B, z_dim)\n",
    "\n",
    "            opt_theta.zero_grad(set_to_none=True)\n",
    "            opt_z.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=amp):\n",
    "                pred = model(coords, z)                       # (B, npts, 1)\n",
    "                loss = sdf_occ_loss(pred, sdf) + lambda_z * z.pow(2).mean()\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt_theta)\n",
    "            scaler.step(opt_z)\n",
    "            scaler.update()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        sched.step()\n",
    "        print(f\"epoch {ep} | train {np.mean(losses):.4e} | lr {sched.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "    return model, latents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e55075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = DeepSDF(z_dim=64, width=128, depth=4).to(device)\n",
    "\n",
    "# latents = nn.Embedding(len(train_ds), 64, sparse=True).to(device)\n",
    "# nn.init.normal_(latents.weight, mean=0.0, std=0.01)\n",
    "\n",
    "# opt_theta = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "# opt_z     = torch.optim.SparseAdam(latents.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399c95a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m y   = b[\u001b[33m\"\u001b[39m\u001b[33msdf\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m     12\u001b[39m z   = latents(torch.tensor(idx, device=device))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m loss = sdf_loss(pred, y) + \u001b[32m1e-4\u001b[39m * z.pow(\u001b[32m2\u001b[39m).mean()  \u001b[38;5;66;03m# small latent L2\u001b[39;00m\n\u001b[32m     15\u001b[39m total = total + loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mDeepSDF.forward\u001b[39m\u001b[34m(self, coords, z)\u001b[39m\n\u001b[32m     13\u001b[39m N = coords.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     14\u001b[39m zrep = z[:,\u001b[38;5;28;01mNone\u001b[39;00m,:].expand(\u001b[32m1\u001b[39m,N,z.shape[-\u001b[32m1\u001b[39m]).reshape(N,-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzrep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/modules/activation.py:133\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/metaPDE/lib/python3.11/site-packages/torch/nn/functional.py:1702\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1700\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace=inplace)\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1703\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1704\u001b[39m     result = torch.relu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # --- train ---\n",
    "# EPOCHS=5\n",
    "# for ep in range(1, EPOCHS+1):\n",
    "#     model.train(); latents.train(); losses=[]\n",
    "#     for batch in train_loader:\n",
    "#         opt_theta.zero_grad(); opt_z.zero_grad()\n",
    "#         total = 0.0\n",
    "#         for b in batch:\n",
    "#             idx = b[\"idx\"]\n",
    "#             x   = b[\"coords\"].to(device)\n",
    "#             y   = b[\"sdf\"].to(device)\n",
    "#             z   = latents(torch.tensor(idx, device=device))\n",
    "#             pred = model(x, z)\n",
    "#             loss = sdf_loss(pred, y) + 1e-4 * z.pow(2).mean()  # small latent L2\n",
    "#             total = total + loss\n",
    "#         (total/len(batch)).backward()\n",
    "#         opt_theta.step(); opt_z.step()\n",
    "#         losses.append(total.item()/len(batch))\n",
    "#     print(f\"epoch {ep}/{EPOCHS} | train {np.mean(losses[-100:]):.4e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaPDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
